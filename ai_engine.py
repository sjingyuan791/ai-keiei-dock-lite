# -*- coding: utf-8 -*-
# ======================================================================
# ai_engine.py â€• AIçµŒå–¶è¨ºæ–­ GPTï¼ˆæœ€é«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼†ãƒ­ã‚¸ãƒƒã‚¯ç‰ˆï¼‰
# ======================================================================
from __future__ import annotations

import json
import os
import textwrap
import traceback
from typing import Any, Dict, List

import streamlit as st
from openai import OpenAI, APIError

# ----------------------------------------------------------------------
# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
# ----------------------------------------------------------------------
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
_DEFAULT_MODEL = "o3-mini"

_SYSTEM_PROMPT = (
    "ã‚ãªãŸã¯è¶…ä¸€æµã®çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
    "çµŒå–¶è€…ãƒ»äº‹æ¥­è²¬ä»»è€…ã«å¯¾ã—ã¦ã€ã‚·ãƒ³ãƒ—ãƒ«ã‹ã¤ä¿¡é ¼æ„Ÿã®ã‚ã‚‹è¡¨ç¾ã§ã€"
    "ç¾å®Ÿçš„ãƒ»å®Ÿè·µçš„ãªæˆ¦ç•¥ãƒ»æ”¹å–„ææ¡ˆã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
    "æƒ…å ±ã¯å¿…ãšå…¨ä½“åƒã‚’ãµã¾ãˆã¦çµ±åˆãƒ»æ•´ç†ã—ã€è«–æ‹ ã¨æ§‹é€ ã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚"
    "å°‚é–€ç”¨èªã¯å¿…è¦æœ€å°é™ã«ã¨ã©ã‚ã€ç„¡é§„ãªèª¬æ˜ãƒ»ãã©ã„è¡¨ç¾ãƒ»ãµã‚ŠãŒãªã¯ä¸è¦ã§ã™ã€‚"
)


def run_gpt(
    prompt: str,
    *,
    model: str = _DEFAULT_MODEL,
    max_tokens: int = 4096,
    temperature: float = 0.0,
) -> str:
    try:
        params: Dict[str, Any] = {
            "model": model,
            "messages": [
                {"role": "system", "content": _SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
            ],
        }
        if model.startswith("o3"):
            params["max_completion_tokens"] = max_tokens
        else:
            params["temperature"] = temperature
            params["max_tokens"] = max_tokens

        rsp = client.chat.completions.create(**params)
        return (rsp.choices[0].message.content or "").strip()
    except APIError as e:
        st.error(f"âŒ OpenAI APIError: {e}")
        return ""


# ======================================================================
# å¤–éƒ¨ç’°å¢ƒåˆ†æï¼ˆGPT-4oæ¨å¥¨ãƒ»Webæ¤œç´¢ãªã—ã§ã‚‚å®‰å®šï¼‰
# ======================================================================
import openai
import streamlit as st


def show_external_environment_analysis_ai(user_input: dict) -> str:
    c = lambda k, d="æœªå…¥åŠ›": user_input.get(k, d)
    # å„è¦³ç‚¹åãƒ»è‹±èªåã‚»ãƒƒãƒˆ
    aspects = [
        ("æ”¿æ²»ãƒ»åˆ¶åº¦", "Politics"),
        ("çµŒæ¸ˆ", "Economy"),
        ("ç¤¾ä¼šãƒ»æ–‡åŒ–", "Society / Culture"),
        ("æŠ€è¡“", "Technology"),
        ("æ¥­ç•Œæ§‹é€ ", "Industry Structure"),
        ("ç«¶åˆãƒã‚¸ã‚·ãƒ§ãƒ³", "Competition Position"),
    ]

    # 1è¦³ç‚¹ã”ã¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆé–¢æ•°


import openai
import streamlit as st
import time


def show_external_environment_analysis_ai(user_input: dict, max_retry=2) -> str:
    c = lambda k, d="æœªå…¥åŠ›": user_input.get(k, d)
    aspects = [
        ("æ”¿æ²»ãƒ»åˆ¶åº¦", "Politics"),
        ("çµŒæ¸ˆ", "Economy"),
        ("ç¤¾ä¼šãƒ»æ–‡åŒ–", "Society / Culture"),
        ("æŠ€è¡“", "Technology"),
        ("æ¥­ç•Œæ§‹é€ ", "Industry Structure"),
        ("ç«¶åˆãƒã‚¸ã‚·ãƒ§ãƒ³", "Competition Position"),
    ]

    def build_prompt(aspect_ja, aspect_en):
        return f"""
ã‚ãªãŸã¯ã€Œä¸­å°ä¼æ¥­å°‚é–€ã®çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã€ã§ã™ã€‚
å¿…ãšã€Œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®å…¬çš„æƒ…å ±ãƒ»ä¿¡é ¼ã§ãã‚‹å°‚é–€ãƒ¡ãƒ‡ã‚£ã‚¢ã€ã®Webæ¤œç´¢çµæœã‚‚æ´»ç”¨ã—ã€
ä¸‹è¨˜ãƒ«ãƒ¼ãƒ«ã§ã€Œ{aspect_ja}ï¼ˆ{aspect_en}ï¼‰ã€ã«é–¢ã™ã‚‹**çµŒå–¶åˆ¤æ–­ã«å½¹ç«‹ã¤â€œæ·±ã„æ´å¯Ÿãƒ»ç¾å ´ç¤ºå”†ãƒ»æ‰“ã¡æ‰‹ãƒ’ãƒ³ãƒˆâ€ã‚’å«ã‚€åšã„è¦ç´„**ã‚’
Markdownã§**200ï½250å­—ã§å‡ºåŠ›**ã—ã¦ãã ã•ã„ã€‚

- å¿…ãšçµŒå–¶åˆ¤æ–­ã‚„ç¾å ´å®Ÿå‹™ã«æœ¬å½“ã«å½¹ç«‹ã¤å…·ä½“çš„è¦–ç‚¹ï¼ˆãªãœé‡è¦ã‹ï¼ä½•ã‚’ã™ã¹ãã‹ï¼ä»–ç¤¾äº‹ä¾‹ï¼ãƒªã‚¹ã‚¯ï¼æ•°å­—ãƒ»ç¾å ´ä¾‹ç­‰ï¼‰ã‚’å«ã‚ã‚‹ã“ã¨
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ç¾…åˆ—ãƒ»ä¸€èˆ¬çš„èª¬æ˜ãƒ»æŠ½è±¡è«–ã¯ç¦æ­¢
- **è£œåŠ©é‡‘ãƒ»åŠ©æˆé‡‘ãƒ»çµ¦ä»˜é‡‘ãªã©ç‰¹å®šã®å…¬çš„åˆ¶åº¦åã‚„é‡‘é¡ã¯ä¸€åˆ‡è¨˜è¼‰ã—ãªã„ã“ã¨ã€‚**
- å¿…ãšä¿¡é ¼ã§ãã‚‹ä¸€æ¬¡ã‚½ãƒ¼ã‚¹ï¼ˆè¡Œæ”¿ç™ºè¡¨ãƒ»æ—¥çµŒ/æ¥­ç•Œæ–°èãƒ»æ”¿åºœWebãƒ»å°‚é–€åª’ä½“ç­‰ï¼‰ã®å‡ºå…¸URLãƒ»åª’ä½“åã‚’2ã¤ä»¥ä¸Šè¨˜è¼‰

ã€ä¼æ¥­æƒ…å ±ã€‘
ä¼šç¤¾å: {c('ä¼šç¤¾åãƒ»å±‹å·')}
æ¥­ç¨®: {c('æ¥­ç¨®ï¼ˆã§ãã‚‹ã ã‘è©³ã—ãï¼‰')}
åœ°åŸŸ: {c('åœ°åŸŸ')}
å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹: {c('ä¸»ãªå•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹')}
é¡§å®¢å±¤: {c('ä¸»ãªé¡§å®¢å±¤')}
å¹´é–“å£²ä¸Šé«˜: {c('å¹´é–“å£²ä¸Šé«˜ï¼ˆãŠãŠã‚ˆãï¼‰')}
ç²—åˆ©ç‡: {c('ç²—åˆ©ç‡ï¼ˆãŠãŠã‚ˆãï¼‰')}
æœ€çµ‚åˆ©ç›Š: {c('æœ€çµ‚åˆ©ç›Šï¼ˆç¨å¼•å¾Œãƒ»ãŠãŠã‚ˆãï¼‰')}
å€Ÿå…¥é‡‘é¡: {c('å€Ÿå…¥é‡‘é¡ï¼ˆã ã„ãŸã„ï¼‰')}
çµŒå–¶ã®å•é¡Œç‚¹: {c('çµŒå–¶ã®å•é¡Œç‚¹')}

ã€Markdownå‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆä¾‹ï¼‰ã€‘
## {aspect_ja} ({aspect_en})
- è¦ç´„: å­£ç¯€å¤‰å‹•ãƒªã‚¹ã‚¯ã®é«˜ã„è‡ªå‹•è»Šæ•´å‚™æ¥­ã§ã¯ç¾é‡‘ç®¡ç†ã‚„åˆ©ç›Šç‡ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã€ä½åˆ©èè³‡åˆ¶åº¦ç­‰ã®æ´»ç”¨ãŒé‡è¦ã€‚è³‡é‡‘è¨ˆç”»ã‚„è²©ä¿ƒæ–½ç­–ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°è¦‹ç›´ã—ã§ã€ç¹å¿™æœŸãƒ»é–‘æ•£æœŸã®åç›Šå®‰å®šåŒ–ãŒå›³ã‚Œã‚‹ã€‚å…¬å¼ã‚µã‚¤ãƒˆç­‰ã§æœ€æ–°æ”¯æ´æƒ…å ±ã‚’å®šæœŸçš„ã«ç¢ºèªã™ã‚‹é‹ç”¨ãŒæ¨å¥¨ã•ã‚Œã‚‹ã€‚
- å‡ºå…¸: æ±äº¬éƒ½ä¸­å°ä¼æ¥­æŒ¯èˆˆå…¬ç¤¾ https://www.tokyo-kosha.or.jp, æ—¥æœ¬çµŒæ¸ˆæ–°è https://www.nikkei.com
"""

    outputs = []
    client = openai.OpenAI()

    for aspect_ja, aspect_en in aspects:
        retry = 0
        while retry <= max_retry:
            prompt = build_prompt(aspect_ja, aspect_en)
            try:
                response = client.chat.completions.create(
                    model="gpt-4.1",  # "gpt-4.1-mini"ã‚„"gpt-4o"ã‚‚å¯
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=1500,
                    temperature=0.7,
                )
                result = response.choices[0].message.content.strip()
            except Exception as e:
                result = f"ã€AIã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã€‘{aspect_ja} ({aspect_en}) : {e}"

            if "ã€AIã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã€‘" not in result:
                outputs.append(result)
                break
            else:
                retry += 1
                time.sleep(2)  # APIåˆ¶é™å¯¾ç­–

        if retry > max_retry:
            outputs.append(f"ã€AIã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã€‘ï¼ˆ{aspect_ja}ï¼‰")

    final_markdown = "\n\n".join(outputs)
    st.session_state["external_output"] = final_markdown
    return final_markdown


# ======================================================================
# AIã‹ã‚‰ã®è³ªå•
# ======================================================================
def deep_dive_questions_ai(user_input: dict) -> list[dict]:
    import textwrap, json, streamlit as st

    basic_json = json.dumps(user_input, ensure_ascii=False)[:2500]
    external = st.session_state.get("external_output", "")[:1800]
    prompt = textwrap.dedent(
        f"""
ã‚ãªãŸã¯ã€Œä¸­å°ä¼æ¥­ã®ç¾å ´ãƒ»å®Ÿå‹™ã‚’ç†ŸçŸ¥ã—ãŸãƒ—ãƒ­çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆå…¼AIã‚³ãƒ¼ãƒã€ã§ã™ã€‚
ä¸‹è¨˜ã€Œèª²é¡Œã€ã€ŒåŸºæœ¬ãƒ»è²¡å‹™æƒ…å ±ã€ã€Œå¤–éƒ¨ç’°å¢ƒåˆ†æã€ã‚’è¸ã¾ãˆã€
ã€ä»Šã¾ã•ã«çµŒå–¶åˆ¤æ–­ã§è¿·ã£ã¦ã„ã‚‹çµŒå–¶è€…ãƒ»ç¾å ´è²¬ä»»è€…ã«â€œæœ¬è³ªã‚’çªããƒ»æ„æ€æ±ºå®šã«ã¤ãªãŒã‚‹é‹­ã„è³ªå•â€ã€‘ã ã‘ã‚’å³é¸ã—ã¦ãã ã•ã„ã€‚

ã€ç‰¹ã«é‡è¦–ã™ã‚‹æŒ‡ç¤ºã€‘
- 5è¦³ç‚¹ï¼ˆçµ„ç¹”ãƒ»äººäº‹ï¼è²¡å‹™ï¼ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ï¼ITãƒ»DXï¼ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã”ã¨ã«ã€Œç¾å ´ãƒ’ã‚¢ãƒªãƒ³ã‚°ã‚„çµŒå–¶åˆ¤æ–­ã§æœ¬å½“ã«å½¹ç«‹ã¤è³ªå•ã€ã‚’**å¿…ãš2å•ãšã¤**ï¼ˆåˆè¨ˆ10å•ä»¥ä¸Šï¼‰å‡ºã™
- ã€Œç¾çŠ¶ã®æ•°å­—ãƒ»ãƒ—ãƒ­ã‚»ã‚¹ãƒ»å½¹å‰²ãƒ»æ„æ€æ±ºå®šãƒ»ç¾å ´æ„Ÿè¦šã€ã«å…·ä½“çš„ã«è¸ã¿è¾¼ã‚€ã“ã¨
- æŠ½è±¡è«–ã‚„ä½¿ã„å›ã—ã®ä¸€èˆ¬è«–ã¯ç¦æ­¢ã€‚â€œä½•ãŒãƒ»èª°ã«ãƒ»ãªãœãƒ»ã©ã†å½±éŸ¿ã—ã¦ã„ã‚‹ã‹â€ã‚’èãå‡ºã™ç²’åº¦ã«
- ã€Œç¾å ´ã®æ•°å€¤ãƒ»é€²æ—ãƒ»æ‹…å½“è€…æ„Ÿè¦šã€ã«ç›´çµã™ã‚‹å…·ä½“è³ªå•ã‚’å¤šãï¼ˆä¾‹ï¼šâ—â—ç‡ã¯ï¼Ÿâ—â—ã«ã©ã‚Œã ã‘æ™‚é–“ãŒã‹ã‹ã‚‹ï¼Ÿâ—â—æ‹…å½“ã¯èª°ï¼Ÿï¼‰
- å„è³ªå•ã”ã¨ã«ã€Œä»Šãªãœãã‚Œã‚’å•ã†ã®ã‹ï¼ˆæ ¹æ‹ ãƒ»30å­—ä»¥å†…ï¼‰ã€ã‚‚å¿…ãšä»˜ä¸ï¼ˆèª²é¡Œã‚„å¤–éƒ¨ç’°å¢ƒã¨ã®é–¢é€£ã‚’æ˜ç¢ºåŒ–ï¼‰
- Yes/Noã‚„æ•°å€¤ãƒ»ç¾å ´ã®ä¸€æ¬¡æƒ…å ±ã§ç­”ãˆã‚‰ã‚Œã‚‹è³ªå•ã‚‚å«ã‚ã‚‹ã“ã¨

ã€ã•ã‚‰ã«ç²¾åº¦ã‚’ä¸Šã’ã‚‹ãŸã‚ã®åˆ¶ç´„ã€‘
- æ¥­ç•Œç‰¹æœ‰ã®äº‹æƒ…ã‚„ç›´é¢èª²é¡Œï¼ˆäººææµå‡ºãƒ»ITåŒ–é…ã‚Œãƒ»æ–°è¦é¡§å®¢ç²å¾—é›£ãªã©ï¼‰ãŒã‚ã‚Œã°ã€å¿…ãšåæ˜ 
- çµŒå–¶è€…ãŒã€Œä»Šã™ãå‹•ãã€ã€Œèª²é¡Œã®æœ¬è³ªã«æ°—ã¥ãã€ã‚ˆã†ãªè³ªå•ãƒ»ç²’åº¦ã‚’å¼·èª¿
- ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ï¼šã€Œç¾å ´ã§â—â—ã®KPIã¯æ˜ç¢ºã§ã™ã‹ï¼Ÿã€ã€Œâ—â—ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ç¾çŠ¶ã©ã“ãŒåœæ»ã—ã¦ã„ã¾ã™ã‹ï¼Ÿã€ãªã©

ã€å‡ºåŠ›ãƒ«ãƒ¼ãƒ«å³å®ˆã€‘
- ä¸‹è¨˜JSONå½¢å¼ã§ã®ã¿å‡ºåŠ›ï¼ˆä»–ã®å‡ºåŠ›ã¯ç¦æ­¢ï¼‰
{{
  "questions": [
    {{"category":"çµ„ç¹”ãƒ»äººäº‹","question":"ï½","rationale":"ï½"}},
    ...
  ]
}}

ã€èª²é¡Œã€‘
{user_input.get('çµŒå–¶ã®å•é¡Œç‚¹','æœªå…¥åŠ›')}
ã€åŸºæœ¬ãƒ»è²¡å‹™æƒ…å ±ã€‘
{basic_json}
ã€å¤–éƒ¨ç’°å¢ƒã€‘
{external}
        """
    )

    schema = {
        "type": "object",
        "properties": {
            "questions": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "category": {"type": "string"},
                        "question": {"type": "string"},
                        "rationale": {"type": "string"},
                    },
                    "required": ["category", "question", "rationale"],
                },
            }
        },
        "required": ["questions"],
    }
    try:
        rsp = client.chat.completions.create(
            model=_DEFAULT_MODEL,
            messages=[
                {"role": "system", "content": _SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
            ],
            functions=[{"name": "make_questions", "parameters": schema}],
            function_call={"name": "make_questions"},
        )
        return json.loads(rsp.choices[0].message.function_call.arguments)["questions"]
    except Exception as e:
        st.warning(f"âš ï¸ Question JSON ç”Ÿæˆå¤±æ•—: {e}")
        return []


# ======================================================================
# SWOTåˆ†æ
# ======================================================================
def show_swot_section_ai(user_input: dict) -> str:
    external = st.session_state.get("external_output", "(å¤–éƒ¨ç’°å¢ƒåˆ†æ æœªå®Ÿè¡Œ)")
    deep_ans = st.session_state.get("deep_dive_questions", [])
    deep_answers = st.session_state.get("deep_dive_answers", {})
    # è³ªå•ï¼‹ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ç­”ã‚’é›†ç´„
    question_and_answers = "\n".join(
        f"{i+1}. {q['category']}ï½œ{q['question']} â†’ {deep_answers.get(f'qq_{i+1}','')}"
        for i, q in enumerate(deep_ans)
    )
    prompt = textwrap.dedent(
        f"""
        ä¸‹è¨˜ã™ã¹ã¦ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€Sï¼ˆå¼·ã¿ï¼‰Wï¼ˆå¼±ã¿ï¼‰Oï¼ˆæ©Ÿä¼šï¼‰Tï¼ˆè„…å¨ï¼‰ã‚’
        ãã‚Œãã‚Œ3ï½5ç‚¹ãšã¤æŒ™ã’ã¦ãã ã•ã„ã€‚å¼·ã¿ãƒ»å¼±ã¿ã«ã¯ã€Œèª²é¡Œã€ã‚„ã€ŒAIã‹ã‚‰ã®è³ªå•å†…å®¹ã€ã‚‚åæ˜ ã•ã›ã¦ãã ã•ã„ã€‚
        å„é …ç›®ã¯ã€Œè¦ç‚¹ï¼‹æ ¹æ‹ ã€ã®ã‚»ãƒƒãƒˆã§ã€è«–ç†çš„ã‹ã¤ç«¯çš„ã«ã€‚

        ã€èª²é¡Œã€‘
        {user_input.get('çµŒå–¶ã®å•é¡Œç‚¹','æœªå…¥åŠ›')}
        ã€åŸºæœ¬ãƒ»è²¡å‹™æƒ…å ±ã€‘
        ä¼šç¤¾å: {user_input.get('ä¼šç¤¾åãƒ»å±‹å·')}
        æ¥­ç¨®: {user_input.get('æ¥­ç¨®ï¼ˆã§ãã‚‹ã ã‘è©³ã—ãï¼‰')}
        åœ°åŸŸ: {user_input.get('åœ°åŸŸ')}
        å¹´é–“å£²ä¸Šé«˜: {user_input.get('å¹´é–“å£²ä¸Šé«˜ï¼ˆãŠãŠã‚ˆãï¼‰')}
        ç²—åˆ©ç‡: {user_input.get('ç²—åˆ©ç‡ï¼ˆãŠãŠã‚ˆãï¼‰')}
        æœ€çµ‚åˆ©ç›Š: {user_input.get('æœ€çµ‚åˆ©ç›Šï¼ˆç¨å¼•å¾Œãƒ»ãŠãŠã‚ˆãï¼‰')}
        å€Ÿå…¥é‡‘é¡: {user_input.get('å€Ÿå…¥é‡‘é¡ï¼ˆã ã„ãŸã„ï¼‰')}

        ã€å¤–éƒ¨ç’°å¢ƒã€‘
        {external}

        ã€AIã‹ã‚‰ã®è³ªå•ãƒ»å›ç­”ã€‘
        {question_and_answers}
        """
    )
    swot = run_gpt(prompt)
    st.session_state["swot_output"] = swot
    return swot


# ======================================================================
# çœŸå› åˆ†æï¼ˆã™ã¹ã¦ã®æƒ…å ±ã‹ã‚‰ï¼‰
# ======================================================================
def root_cause_analysis_ai(user_input: dict) -> str:
    import textwrap, streamlit as st
    import re

    external = st.session_state.get("external_output", "(å¤–éƒ¨ç’°å¢ƒåˆ†æ æœªå®Ÿè¡Œ)")
    swot = st.session_state.get("swot_output", "(SWOT æœªå®Ÿè¡Œ)")
    deep_ans = st.session_state.get("deep_dive_questions", [])
    deep_answers = st.session_state.get("deep_dive_answers", {})
    question_and_answers = "\n".join(
        f"{i+1}. {q['category']}ï½œ{q['question']} â†’ {deep_answers.get(f'qq_{i+1}','')}"
        for i, q in enumerate(deep_ans)
    )

    prompt = textwrap.dedent(
        f"""
ã‚ãªãŸã¯ç¾å ´ãƒ»çµŒå–¶ã«å¼·ã„è¶…ä¸€æµã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä¸‹è¨˜æƒ…å ±ã‚’ã‚‚ã¨ã«ã€å¿…ãšä»¥ä¸‹ã®é †ã§æ§‹é€ çš„ã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

1. # ç¾åœ¨ã®å•é¡Œç‚¹
  - ç®‡æ¡æ›¸ãã§2ï½5ç‚¹ç¨‹åº¦ã€ç¾è±¡ã‚„ç—‡çŠ¶ã‚’å…·ä½“çš„ã«ï¼ˆã§ãã‚Œã°æ•°å­—ãƒ»ç¾å ´è¨¼æ‹ ã‚‚ï¼‰ã€‚
2. # ä¸»ãªåŸå› 
  - ç®‡æ¡æ›¸ãã§2ï½3ç‚¹ã€ãªãœä¸Šè¨˜å•é¡ŒãŒèµ·ã“ã£ã¦ã„ã‚‹ã‹ã€è¦å› ã‚’ç°¡æ½”ã«ã€‚
3. # çœŸå› ï¼ˆRoot Causeï¼‰
  - ä¸€è¨€ã§â€œæœ€å¤§ã®åŸå› â€ã‚’ç‰¹å®šã€‚ãªãœã“ã‚ŒãŒçœŸå› ã‹ã€ç†ç”±ãƒ»æ ¹æ‹ ã‚‚1æ–‡ã§è¿°ã¹ã‚‹ã€‚

ã€å‡ºåŠ›ä¾‹ã€‘
# ç¾åœ¨ã®å•é¡Œç‚¹
- å£²ä¸ŠãŒ3æœŸé€£ç¶šã§æ¸›å°‘
- ç²—åˆ©ç‡ãŒæ˜¨å¹´30%â†’ä»Šå¹´22%ã«ä½ä¸‹
- æ–°è¦é¡§å®¢é–‹æ‹“ãŒé€²ã‚“ã§ã„ãªã„

# ä¸»ãªåŸå› 
- æ—¢å­˜é¡§å®¢ã¸ã®å€¤å¼•ãå¯¾å¿œãŒå¢—åŠ 
- å–¶æ¥­æ´»å‹•ãŒå±äººçš„ã§æ–°è¦é–‹æ‹“ãŒå¼±ã„

# çœŸå› ï¼ˆRoot Causeï¼‰
**å–¶æ¥­æˆ¦ç•¥ã®å¤šè§’åŒ–ä¸è¶³**
ãªãœã“ã‚ŒãŒçœŸå› ã‹ï¼šæ—¢å­˜é¡§å®¢ä¾å­˜åº¦ãŒé«˜ãã€æ–°è¦å¸‚å ´é–‹æ‹“ãƒªã‚½ãƒ¼ã‚¹ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€‚

---
ã€å•é¡Œã€‘
{user_input.get('çµŒå–¶ã®å•é¡Œç‚¹','æœªå…¥åŠ›')}
ã€åŸºæœ¬ãƒ»è²¡å‹™æƒ…å ±ã€‘
ä¼šç¤¾å: {user_input.get('ä¼šç¤¾åãƒ»å±‹å·')}
æ¥­ç¨®: {user_input.get('æ¥­ç¨®ï¼ˆã§ãã‚‹ã ã‘è©³ã—ãï¼‰')}
åœ°åŸŸ: {user_input.get('åœ°åŸŸ')}
å¹´é–“å£²ä¸Šé«˜: {user_input.get('å¹´é–“å£²ä¸Šé«˜ï¼ˆãŠãŠã‚ˆãï¼‰')}
ç²—åˆ©ç‡: {user_input.get('ç²—åˆ©ç‡ï¼ˆãŠãŠã‚ˆãï¼‰')}
æœ€çµ‚åˆ©ç›Š: {user_input.get('æœ€çµ‚åˆ©ç›Šï¼ˆç¨å¼•å¾Œãƒ»ãŠãŠã‚ˆãï¼‰')}
å€Ÿå…¥é‡‘é¡: {user_input.get('å€Ÿå…¥é‡‘é¡ï¼ˆã ã„ãŸã„ï¼‰')}

ã€å¤–éƒ¨ç’°å¢ƒã€‘
{external}

ã€AIã‹ã‚‰ã®è³ªå•ãƒ»å›ç­”ã€‘
{question_and_answers}

ã€SWOTåˆ†æã€‘
{swot}
    """
    )

    txt = run_gpt(prompt)
    # å¿µã®ãŸã‚HTMLã‚¿ã‚°é™¤å»ï¼ˆAIãŒä¸‡ä¸€ã‚¿ã‚°ã‚’è¿”ã—ã¦ã‚‚å¤§ä¸ˆå¤«ãªã‚ˆã†ã«ï¼‰
    clean_txt = re.sub(r"<[^>]+>", "", txt)
    st.session_state["root_cause_output"] = clean_txt
    return clean_txt


# ======================================================================
# æ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆï¼‹çµ±åˆè©•ä¾¡
# ======================================================================
def action_with_eval_ai(user_input: dict) -> Dict[str, Any]:
    import textwrap, streamlit as st, json, traceback

    external = st.session_state.get("external_output", "")
    swot = st.session_state.get("swot_output", "")
    root = st.session_state.get("root_cause_output", "")
    deep_ans = st.session_state.get("deep_dive_questions", [])
    deep_answers = st.session_state.get("deep_dive_answers", {})
    question_and_answers = "\n".join(
        f"{i+1}. {q['category']}ï½œ{q['question']} â†’ {deep_answers.get(f'qq_{i+1}','')}"
        for i, q in enumerate(deep_ans)
    )
    prompt = textwrap.dedent(
        f"""
ä¸‹è¨˜ã®å…¨æƒ…å ±ã‚’çµ±åˆã—ã€ã€Œæœ€ã‚‚åŠ¹æœçš„ãªæ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆ1ï½2å€‹ï¼‰ã€ã‚’ã€ğŸš©æœ€å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘ã¨ã—ã¦å¿…ãš"æœ€ä¸Šä½ã§ç›®ç«‹ã¤ã‚ˆã†ã«"ã€ã•ã‚‰ã«é‡è¦ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚‚åŠ ãˆã¦è¨ˆ3ã¤ææ¡ˆã—ã¦ãã ã•ã„ã€‚
ã€é‡è¦ã€‘æœ€å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆis_best:trueï¼‰ã¯ã€å¿…ãšåˆè¨ˆç‚¹ï¼ˆtotalï¼‰ãŒæœ€å¤§ã®ã‚‚ã®ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚
è¤‡æ•°åŒç‚¹ãŒã‚ã‚‹å ´åˆã¯ã€æœ€ã‚‚å³åŠ¹æ€§ãƒ»é‡è¦æ€§ãŒé«˜ã„æ–½ç­–1ã¤ã®ã¿is_best:trueã€ãã‚Œä»¥å¤–ã¯is_best:falseã¨ã—ã¦ãã ã•ã„ã€‚

å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«ã€ä¸‹è¨˜13é …ç›®ã‚’å¿…ãšJSONå½¢å¼ã§è¨˜è¿°ã—ã¦ãã ã•ã„ï¼ˆç©ºæ¬„ç¦æ­¢ï¼‰ã€‚

1. titleï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€‚æœ€å„ªå…ˆã¯"ã€ğŸš©æœ€å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘"ã§å§‹ã‚ã‚‹ï¼‰
2. contentï¼ˆç¾å ´ã§ä»Šã™ãç€æ‰‹ã§ãã‚‹å…·ä½“ç­–ã‚‚æ˜è¨˜ï¼‰
3. evidenceï¼ˆæ ¹æ‹ ãƒ‡ãƒ¼ã‚¿ãƒ»æ¥­ç•Œå¹³å‡ãƒ»ä»–ç¤¾å®Ÿä¾‹ãƒ»å…¬çš„å‡ºå…¸ã€‚å¿…ãš1ã¤ã¯URLã¾ãŸã¯åª’ä½“åã‚’å«ã‚ã‚‹ï¼‰
4. riskï¼ˆã‚„ã‚‰ãªã„å ´åˆã®ãƒªã‚¹ã‚¯ã€‚1è¡Œã§æå¤±ãƒªã‚¹ã‚¯ãƒ»å¤±æ•—ä¾‹ã‚’å…·ä½“çš„ã«ï¼‰
5. kpiï¼ˆå¿…ãšå…·ä½“çš„ãªæ•°å€¤ãƒ»æŒ‡æ¨™ã€‚ç©ºæ¬„ç¦æ­¢ï¼‰
6. Vï¼ˆçµŒæ¸ˆä¾¡å€¤ï¼š1ï½10ç‚¹ï¼‰ã¨ root_Vï¼ˆãã®æ ¹æ‹ ã‚’30å­—ä»¥å†…ã§ï¼‰
7. Rï¼ˆå¸Œå°‘æ€§ï¼š1ï½10ç‚¹ï¼‰ã¨ root_Rï¼ˆãã®æ ¹æ‹ ã‚’30å­—ä»¥å†…ã§ï¼‰
8. Iï¼ˆæ¨¡å€£å›°é›£æ€§ï¼š1ï½10ç‚¹ï¼‰ã¨ root_Iï¼ˆãã®æ ¹æ‹ ã‚’30å­—ä»¥å†…ã§ï¼‰
9. Oï¼ˆçµ„ç¹”é©åˆæ€§ï¼š1ï½10ç‚¹ï¼‰ã¨ root_Oï¼ˆãã®æ ¹æ‹ ã‚’30å­—ä»¥å†…ã§ï¼‰
10. å¸‚å ´æˆé•·æ€§ï¼ˆ1ï½10ç‚¹ï¼‰ã¨ root_å¸‚å ´æˆé•·æ€§ï¼ˆãã®æ ¹æ‹ ã‚’30å­—ä»¥å†…ã§ï¼‰
11. å®Ÿè¡Œé›£æ˜“åº¦ï¼ˆ1ï½10ç‚¹ï¼‰ã¨ root_å®Ÿè¡Œé›£æ˜“åº¦ï¼ˆãã®æ ¹æ‹ ã‚’30å­—ä»¥å†…ã§ï¼‰
12. æŠ•è³‡åŠ¹ç‡ï¼ˆ1ï½10ç‚¹ï¼‰ã¨ root_æŠ•è³‡åŠ¹ç‡ï¼ˆãã®æ ¹æ‹ ã‚’30å­—ä»¥å†…ã§ï¼‰
13. é¡§å®¢è©•ä¾¡ï¼ˆ1ï½10ç‚¹ï¼‰ã¨ root_é¡§å®¢è©•ä¾¡ï¼ˆãã®æ ¹æ‹ ã‚’30å­—ä»¥å†…ã§ï¼‰
14. ãƒªã‚¹ã‚¯ï¼ˆ1ï½10ç‚¹ï¼‰ã¨ root_ãƒªã‚¹ã‚¯ï¼ˆãã®æ ¹æ‹ ã‚’30å­—ä»¥å†…ã§ï¼‰
15. totalï¼ˆåˆè¨ˆç‚¹æ•°ï¼‰, rankï¼ˆA/B/Cï¼‰, is_bestï¼ˆbool/æœ€å„ªå…ˆtrueï¼‰

ã€JSONå‡ºåŠ›ä¾‹ã€‘
{{
  "actions": [
    {{
      "title": "ã€ğŸš©æœ€å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘ç‰¹å®šæ•´å‚™èªè¨¼ã¨é›»å­æ•´å‚™å¯¾å¿œä½“åˆ¶ã®å³æ™‚å¼·åŒ–",
      "content": "...",
      "evidence": "...",
      "risk": "...",
      "kpi": "...",
      "V": 8, "root_V": "ç²—åˆ©ç‡æ”¹å–„ãŒè¦‹è¾¼ã‚ã‚‹",
      "R": 7, "root_R": "ä»–ç¤¾ã¨ã®å·®åˆ¥åŒ–è¦ç´ ",
      "I": 8, "root_I": "å°‚é–€ãƒã‚¦ãƒã‚¦ãŒå¿…è¦",
      "O": 8, "root_O": "æ—¢å­˜çµ„ç¹”ã§å®Ÿè¡Œå¯èƒ½",
      "å¸‚å ´æˆé•·æ€§": 9, "root_å¸‚å ´æˆé•·æ€§": "é–¢é€£å¸‚å ´ãŒæ‹¡å¤§ä¸­",
      "å®Ÿè¡Œé›£æ˜“åº¦": 7, "root_å®Ÿè¡Œé›£æ˜“åº¦": "æ—¢å­˜äººå“¡ã§å¯¾å¿œå¯èƒ½",
      "æŠ•è³‡åŠ¹ç‡": 8, "root_æŠ•è³‡åŠ¹ç‡": "ROIé«˜ã„",
      "é¡§å®¢è©•ä¾¡": 8, "root_é¡§å®¢è©•ä¾¡": "é¡§å®¢æº€è¶³åº¦å‘ä¸Šã«å¯„ä¸",
      "ãƒªã‚¹ã‚¯": 6, "root_ãƒªã‚¹ã‚¯": "æ³•è¦åˆ¶ãƒªã‚¹ã‚¯ä½ã„",
      "total": 41,
      "rank": "A",
      "is_best": true
    }},
    ...
  ]
}}

ã€å¤–éƒ¨ç’°å¢ƒã€‘
{external}

ã€AIã‹ã‚‰ã®è³ªå•ãƒ»å›ç­”ã€‘
{question_and_answers}

ã€SWOTåˆ†æã€‘
{swot}

ã€çœŸå› åˆ†æã€‘
{root}
        """
    )
    schema = {
        "type": "object",
        "properties": {
            "actions": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "title": {"type": "string"},
                        "content": {"type": "string"},
                        "evidence": {"type": "string"},
                        "risk": {"type": "string"},
                        "kpi": {"type": "string"},
                        "V": {"type": "integer"},
                        "root_V": {"type": "string"},
                        "R": {"type": "integer"},
                        "root_R": {"type": "string"},
                        "I": {"type": "integer"},
                        "root_I": {"type": "string"},
                        "O": {"type": "integer"},
                        "root_O": {"type": "string"},
                        "å¸‚å ´æˆé•·æ€§": {"type": "integer"},
                        "root_å¸‚å ´æˆé•·æ€§": {"type": "string"},
                        "å®Ÿè¡Œé›£æ˜“åº¦": {"type": "integer"},
                        "root_å®Ÿè¡Œé›£æ˜“åº¦": {"type": "string"},
                        "æŠ•è³‡åŠ¹ç‡": {"type": "integer"},
                        "root_æŠ•è³‡åŠ¹ç‡": {"type": "string"},
                        "é¡§å®¢è©•ä¾¡": {"type": "integer"},
                        "root_é¡§å®¢è©•ä¾¡": {"type": "string"},
                        "ãƒªã‚¹ã‚¯": {"type": "integer"},
                        "root_ãƒªã‚¹ã‚¯": {"type": "string"},
                        "total": {"type": "integer"},
                        "rank": {"type": "string"},
                        "is_best": {"type": "boolean"},
                    },
                    "required": [
                        "title",
                        "content",
                        "evidence",
                        "risk",
                        "kpi",
                        "V",
                        "root_V",
                        "R",
                        "root_R",
                        "I",
                        "root_I",
                        "O",
                        "root_O",
                        "å¸‚å ´æˆé•·æ€§",
                        "root_å¸‚å ´æˆé•·æ€§",
                        "å®Ÿè¡Œé›£æ˜“åº¦",
                        "root_å®Ÿè¡Œé›£æ˜“åº¦",
                        "æŠ•è³‡åŠ¹ç‡",
                        "root_æŠ•è³‡åŠ¹ç‡",
                        "é¡§å®¢è©•ä¾¡",
                        "root_é¡§å®¢è©•ä¾¡",
                        "ãƒªã‚¹ã‚¯",
                        "root_ãƒªã‚¹ã‚¯",
                        "total",
                        "rank",
                        "is_best",
                    ],
                },
            }
        },
        "required": ["actions"],
    }
    try:
        rsp = client.chat.completions.create(
            model=_DEFAULT_MODEL,
            messages=[
                {"role": "system", "content": _SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
            ],
            functions=[{"name": "make_actions", "parameters": schema}],
            function_call={"name": "make_actions"},
        )

        raw = json.loads(rsp.choices[0].message.function_call.arguments)["actions"]

        # åˆè¨ˆç‚¹æœ€å¤§ã®ã‚‚ã®ã ã‘ is_best=True ã«è£œæ­£ï¼ˆè¤‡æ•°ã‚ã‚Œã°æœ€åˆã®1ã¤ã®ã¿Trueï¼‰
        max_score = max(a.get("total", 0) for a in raw)
        first_flag = False
        for a in raw:
            if a.get("total", 0) == max_score and not first_flag:
                a["is_best"] = True
                first_flag = True
            else:
                a["is_best"] = False

    except Exception as e:
        st.session_state["action_error_trace"] = traceback.format_exc()
        st.error(f"âš ï¸ Action+Eval ç”Ÿæˆå¤±æ•—: {e}")
        return {"actions_md": "", "evaluations": []}

    # Markdownç”¨å‡ºåŠ›ï¼ˆæœ€å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¢ã‚¤ã‚³ãƒ³å¼·èª¿ï¼ï¼‰
    md = []
    for a in raw:
        if a.get("is_best"):
            md.append(
                f"---\n### ğŸš©ã€æœ€å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘{a['title'].replace('ã€ğŸš©æœ€å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘','')}\n"
            )
        else:
            md.append(f"---\n### {a.get('title','')}\n")
        md.append(a.get("content", ""))
        md.append(f"- **æ ¹æ‹ ãƒ‡ãƒ¼ã‚¿ãƒ»å®Ÿä¾‹**: {a.get('evidence','')}")
        md.append(f"- **ã‚„ã‚‰ãªã„å ´åˆã®ãƒªã‚¹ã‚¯**: {a.get('risk','')}")
        md.append(f"- **KPI**: {a.get('kpi','')}")
        md.append(f"- **ç·åˆç‚¹**: {a.get('total','')} / **Rank**: {a.get('rank','')}")
    return {"actions_md": "\n".join(md), "evaluations": raw}


# ----------------------------------------------------------------------
# å…¬é–‹ã‚·ãƒ³ãƒœãƒ«
# ----------------------------------------------------------------------
__all__ = [
    "show_external_environment_analysis_ai",
    "deep_dive_questions_ai",
    "show_swot_section_ai",
    "root_cause_analysis_ai",
    "action_with_eval_ai",
    "run_gpt",
]
